---
title: 'Data Analytics: Lab 2'
author: "Brendan Donnelly"
date: "October 2, 2020"
output:
  pdf_document: default
  html_document: default
---

### Lab 2 part 1

## Measures of central tendancy for EPI,DALY vars
```{r}
library(ggplot2)
EPI<-read.csv("/Users/donneb/Documents/DataAnalytics/EPI_data.csv")
summary(EPI$EPI)
fivenum(EPI$EPI, na.rm = T)
summary(EPI$DALY)#stats
fivenum(EPI$DALY, na.rm = T)

# Histograms of both vars
histEPI<- ggplot(EPI, aes(x=EPI)) + geom_histogram(binwidth = 5, na.rm=TRUE)
histEPI +labs(title = "EPI Histogram")

histDALY<- ggplot(EPI, aes(x=DALY)) + geom_histogram(binwidth = 5, na.rm=TRUE, title = "Daly Histogram")
histDALY +labs(title = "DALY Histogram")
```

## Comparing ENVHEALTH and ECOSYSTEM's Relationship

### boxplot,normal distribution plot comparing
```{r clim}
#boxplot
boxplot(EPI$ENVHEALTH, EPI$ECOSYSTEM, names = c('ENVHEALTH','ECOSYSTEM'))

#normal dist plots
qqplot(EPI$ENVHEALTH, EPI$ECOSYSTEM)
```

# Determining Most Important Factor in EPI Regression
```{r}
#getting a feel for relationships
plot(EPI[c(14,15,17,18,19,20,26)])
```

## Linear and Least Squares ENVHEALTH
```{r}
ENVHEALTH <- EPI$ENVHEALTH
DALY <- EPI$DALY
AIR_H<- EPI$AIR_H
WATER_H<- EPI$WATER_H

# spread of all linear regression vars, w/ ENVHEALTh 1

boxplot(ENVHEALTH,DALY,AIR_H,WATER_H, names = c("ENVHEALTH", "DALY", "AIR_H", "WATER_H"))

lmENVH<-lm(ENVHEALTH~DALY+AIR_H+WATER_H)
lmENVH
summary(lmENVH)
cENVH<-coef(lmENVH)
cENVH

DALYNEW<-c(seq(5,95,5))
AIR_HNEW<-c(seq(5,95,5))
WATER_HNEW<-c(seq(5,95,5))

NEW <-data.frame(DALYNEW,AIR_HNEW,WATER_HNEW)
pENV<- predict(lmENVH,NEW,interval = "pred")
cENV<- predict(lmENVH,NEW,interval = "conf")
```

#### DALY had the largest impact on the regression function compared to AIR_H, and WATER_H to determine ENVHEALTH. Predictions did not turn out well due to a resulting error in row counts in EPI vs. the NEW dataset will try to fix. 

## regression on AIR_E
```{r}
DALYNEW<-c(seq(5,95,5))
AIR_HNEW<-c(seq(5,95,5))
WATER_HNEW<-c(seq(5,95,5))
NEW <-data.frame(DALYNEW,AIR_HNEW,WATER_HNEW)

AIR_E <- EPI$AIR_E

boxplot(AIR_E,DALY,AIR_H,WATER_H, names = c("AIR_E", "DALY", "AIR_H", "WATER_H"))

lmAIR_E<-lm(AIR_E~DALY+AIR_H+WATER_H)
lmAIR_E
summary(lmAIR_E)
cAIR_E<-coef(lmAIR_E)

pENV<- predict(lmAIR_E,NEW,interval = "prediction")
cENV<- predict(lmAIR_E,NEW,interval = "confidence")
```

#### In this regression the variable AIR_H had the largest pull compared to WATER_H and DALY in Determining AIR_E however the intercept had the strongest indicating a bad regression model


## regression on CLIMATE
```{r}
CLIMATE <- EPI$CLIMATE
boxplot(CLIMATE,DALY,AIR_H,WATER_H, names = c("CLIMATE", "DALY", "AIR_H", "WATER_H")) 
        
lmCLIMATE<-lm(CLIMATE~DALY+AIR_H+WATER_H)
lmCLIMATE
summary(lmCLIMATE)
cCLIMATE<-coef(lmCLIMATE)

pENV<- predict(lmCLIMATE,NEW,interval = "prediction")
cENV<- predict(lmCLIMATE,NEW,interval = "confidence")
```
#### In this regression the variables DALY,AIR_H,and WATER_H all were insignificant variables in the regression model to determine climate

# Lab 2 part 2

## Exercise 1: Regression
### Data Exploration
````{r}
mult_reg<-read.csv("/Users/donneb/Documents/DataAnalytics/dataset_multipleRegression.csv")
#EDA of data set
head(mult_reg)
plot(mult_reg[])
```

### regression model 1: Exploring regression model 1 factoring HGRAD, UNEM
```{r}
#Exploring regression model 1 factoring HGRAD, UNEM
lmROLL<- lm(ROLL~HGRAD+UNEM, data = mult_reg)
lmROLL

#will only plot lm residuals and all for this example
plot(lmROLL)
summary(lmROLL)
lmROLL$coefficients
```

### prediction for model 1 w/ UNEM=7%, HGRAD=90,000
```{r }
#prediction 1 based on model 1
pred_nextyear1 <-predict(lmROLL, newdata=data.frame(HGRAD = 90000 , UNEM =.07 ))
pred_nextyear1

```

### new model factoring HGRAD,UNEM,INC
````{r}
#Exploring regression model 1 factoring HGRAD, UNEM
lmROLL2<- lm(ROLL~HGRAD+UNEM+INC, data = mult_reg)
lmROLL2
summary(lmROLL2)
```

### prediction factoring per capita income (INC = 25,000)
```{r}

#prediction 1 based on model 1
pred_nextyear2 <-predict(lmROLL2, newdata=data.frame(HGRAD = 90000 , UNEM =.07, INC = 25000 ))
pred_nextyear2
```

## Exercise 2
```{r }
# summary of data set
abalone<-read.csv("/Users/donneb/Documents/DataAnalytics/abalone.csv")
colnames(abalone) <- c("sex", "length", 'diameter', 'height', 'whole_weight', 'shucked_wieght', 'viscera_wieght', 'shell_weight', 'rings' )
summary(abalone)
str(abalone)
summary(abalone$rings)
```
### grouping by age rings
```{r}
# age rings
abalone$rings <- as.numeric(abalone$rings)
abalone$rings <- cut(abalone$rings, br=c(-1,8,11,35), labels = c("young", 'adult', 'old'))
abalone$rings <- as.factor(abalone$rings)

summary(abalone$rings)
```

# Copying dataset,removing non numeric for KNN, and normalizing
```{r}
aba<- abalone
aba$sex <-NULL

#  normalize the data using min max normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

aba[1:7] <- as.data.frame(lapply(aba[1:7], normalize))
summary(aba$shucked_wieght)
```
# Its KNN Time!
```{r}
ind <- sample(2, nrow(aba), replace=TRUE, prob=c(0.7, 0.3))

#test,train
KNNtrain <- aba[ind==1,]
KNNtest <- aba[ind==2,]

# set k to sqrt(2918) ~ 54.02 round up to 55
library(class)
KNNpred<- knn(train = KNNtrain[1:7], test = KNNtest[1:7], cl = KNNtrain$rings, k=55)
KNNpred
table(KNNpred)
```

# Exercise 3 - KNN exploration
```{r}
library(ggplot2)
iris_copy = iris
#drop species column
iris_copy$Species = NULL
head(iris_copy)

str(iris_copy)
summary(iris_copy) 
sapply(iris_copy[,-5], var)

iris_copy[,3:4]

#setting seeds & kmeans function
set.seed(300)
k.max <- 12
wss<- sapply(1:k.max,function(k){kmeans(iris_copy[],k,nstart = 20,iter.max = 1000)$tot.withinss})
wss
plot(1:k.max,wss, type= "b", xlab = "Number of clusters(k)", ylab = "Within cluster sum of squares")
icluster <- kmeans(iris_copy[,3:4],3,nstart = 20)
correct_table<- table(iris[,5],icluster$cluster)
correct_table
```
#### The resulting clusters that were created under this KNN clustering were not entirely correct. The 2nd group 100% matched the setosa species However the versicolor was split between the 1st and 3rd group with 48 in the 3rd and 2 in the 1st. In addition, the the virginica clustering was split 46 in the 1st group, and 4 in the 3rd group. This indicates room for improvement and perhaps parameter adjustments

## Exercise 4
### sample values sample_n

```{r}
library(dplyr)
sample_n(EPI[14],5)
sample_n(EPI[17],5)
```

### sample_frac
```{r}
sample_frac(EPI[14],.1)
sample_frac(EPI[17],.1)
```

### arrange by descending

```{r }
by_DALY <- EPI %>% group_by(DALY)
by_DALY %>% arrange(desc(DALY), .by_group = TRUE)
by_EPI <- EPI %>% group_by(EPI)
by_EPI %>% arrange(desc(EPI), .by_group = TRUE)
```

### mutate
```{r}
#should have done this a while ago
EPI_copy<- EPI

#mutate functions
mutate(EPI_copy, double_EPI = EPI * 2)
mutate(EPI_copy, double_DALY = DALY * 2)
```

### EPI,DALY mean
```{r}
EPI %>%
  summarize(EPI_mean = mean(EPI, na.rm= TRUE))

EPI %>%
  summarize(DALY_mean = mean(DALY, na.rm= TRUE))

```